# Pluggable Server Request Handlers #

A server needs a way to respond to a `SYN_STREAM`. Based on

- the headers in the `SYN_STREAM`, and

- perhaps data from incoming frames

something needs to

- generate a set of response headers

- generate a series of data chunks for the response

I think that the simplest type that might work looks like this:

    [(HeaderName, HeaderValue)
    -> IO (Maybe ByteString)
    -> IO ([(HeaderName, HeaderValue)], IO (Maybe ByteString))

Here, the values of type

    IO (Maybe ByteString)

are IO actions that either fetch the next chunk of data, or say that
there is no more data to be had. On the input, this IO action yields
data from a request body; in the output, it yields data for the
response body. We could take a page out of attoparsec's book and use
an empty byte string to represent end-of-input, which would simplify
the type slightly.

One problem with this is the type does not account for the fact that
`HEADERS` frames could arrive from the client for the same
stream. This suggests that we also need actions that return more
headers, and that the type should really be:

    [(HeaderName, HeaderValue)]
    -> IO (Maybe ByteString)
    -> IO (Maybe [(HeaderName, HeaderValue)])
    -> IO ([(HeaderName, HeaderValue)],
           IO (Maybe [(HeaderName, HeaderValue)]),
           IO (Maybe ByteString))

In the result, the header list is for the `SYN_REPLY` frame that
answers the `SYN_STREAM`. Subsequent headers read from the IO action
will result in `HEADERS` frames, and subsequent bytes read from the
second IO action will result in data frames. The data may need to be
split or buffered in order to form data frames of an optimal length.

We'll call a function of this type a *request handler*. The server
options should include a request handler that is used in response to
all `SYN_STREAM` frames.

## Preserving relative order of headers and data ##

On May 1, 2012, I gave a talk on spdy-base at an EFPUG, and presented
a slightly more readable form of the handler type above, where I
replaced `[(HeaderName,HeaderValue)]` with `HeaderBlock`:

    HeaderBlock
    -> IO (Maybe ByteString)
    -> IO (Maybe HeaderBlock)
    -> IO (HeaderBlock,
           IO (Maybe HeaderBlock),
           IO (Maybe ByteString))

Dale Hagglund pointed out that one small problem with this type is it
loses the relative ordering of chunks of headers and chunks of
data. For example, if the request entails the following additional
frames:

    HEADERS
    DATA
    HEADERS
    DATA
    DATA

then the request handler cannot tell that the first `HEADERS` frame
arrived just before the first `DATA` frame, and that the second
`HEADERS` frame was followed by two more `DATA` frames. For serving
HTTP requests over SPDY this probably doesn't matter. But, strictly
speaking, it's probably a good idea to preserve this information.

This suggests a slightly different type for the handler:

    HeaderBlock
    -> IO (Maybe (Either ByteString HeaderBlock)
    -> IO (HeaderBlock,
           IO (Maybe (Either ByteString HeaderBlock)))


## Signaling nothing except the initial header block in a response ##

It's possible that a response does not need to send anything except
the initial set of response headers. For example, this is surely the
case for many HTTP error responses. For this kind of response, it's
possible for a request handler to return something like this

     (HeaderBlock [(":status", "404"),
                   (":version", "HTTP/1.1")],
      return Nothing)

The problem with this is that the code that sends the `SYN_REPLY`
frame with the initial header block does not know whether to set the
`FIN` flag on that frame. It must instead obtain the `Nothing` by
extracting the result of the first IO action. This is fine in cases
where the IO action really is `return Nothing`. However, in cases
where the IO action may block waiting for incoming frames, this means
we will not send the `SYN_REPLY` as early as we should. In fact, if
the remote endpoint waits to send more data or headers until it
receives the `SYN_REPLY`, we've got a live lock.

One reasonable way to avoid this problem involves a slight change in
the request handler type:

    HeaderBlock
    -> Maybe (IO (Maybe (Either ByteString HeaderBlock))
    -> IO (HeaderBlock,
           Maybe (IO (Maybe (Either ByteString HeaderBlock))))

If there is nothing but a header block in either the request (because
the `SYN_STREAM` frame had the `FIN` flag set) or nothing but a header
block in the response, then we don't have an IO action for getting
more headers and data.

## Collapsing `Maybe (Either ByteString HeaderBlock)` ##

Instead of the rather long-winded

    Maybe (Either ByteString HeaderBlock)

I thought it would be a good idea to have a `StreamContent` type:

    data StreamContent =
      EndOfStream |
      MoreHeaders HeaderBlock |
      MoreData ByteString

This makes the meaning of the types a little clearer, and it makes a
request handler look like:

    HeaderBlock
    -> Maybe (IO StreamContent)
    -> IO (HeaderBlock,
           Maybe (IO StreamContent)))


## Hmm. What about flow control? ##

There is a problem with the request handler type: it doesn't allow us
to deal with flow control properly. The IO action

    IO StreamContent

implies a pull model. The request handler reads the initial set of
headers, and then pulls the contents of the request side of the stream
as it can process it. This implies that all the flow control has to be
handled within the server infrastructure, and data chunks have to be
buffered. This is different from what we did with the SPDY client,
where the `StreamOptions` type holds a data consumer with the type

    Maybe ByteString -> IO DeltaWindowSize

The idea here was that a stream did not buffer the data it received:
it was handed off immediately to the data consumer, which would report
back the change in window size. Note that this is a *push* approach.

It would be nice if we could adopt a single approach in the `EndPoint`
module that encompassed both the client and server cases.

So if we were to adopt a push approach, what would the type of a
request handler look like? Let's call the user of the server
infrastructure the *web application*, and the user of the client
infrastructure the *client application*.

- we want to push the the request body and subsequent headers to the
  web application. This suggests that the handler for incoming headers
  and bytes have type:

      StreamContent -> IO DeltaWindowSize

  This function is called by the server infrastructure to push
  incoming frames and headers to the web application; it also
  explictly signals the end of the stream. Since it must be called by
  the server infrastructure, the function must be part of the *result*
  of the request handler.

- if we were to use a completely push-based model, we'd want the web
  app to push response headers and data to the server
  infrastructure. Since the web app must do this by calling a
  function, that function must be an argument to the request handler.

This all suggests that the type of a request handler be

    HeaderBlock
    -- ^ Initial request headers.
    -> (StreamContent -> IO DeltaWindowSize)
    -- ^ Function to push response content.
    -> IO (HeaderBlock, StreamContent -> IO DeltaWindowSize)
    -- ^ Response headers, function to push further request content.

This type is a little bit confusing, because the inputs and outputs
are each partly for the request and partly for the response. There is
also the extra complication of figuring out what `DeltaWindowSize` to
return.

Let's make sure that the response push function has the right type for
dealing with flow control. In the server infrastructure, we need to
track the remaining window size for the client side. By default, we'd
assume that the window size is 64KB. When we push a chunk of data, the
server infrastructure must

- send a `DATA` frame to the client side

- decrement the window size for the stream

At this point, the client has not sent a `WINDOW_UPDATE` frame to tell
the server what the change in window size is. Note that
`DeltaWindowSize` is by design positive. Therefore, the type

    StreamContent -> IO DeltaWindowSize

does not make sense for pushing response content: the server
infrastructure cannot really return anything but zero, since pushing
data decreases the window. There must be a separate function through
which the server infrastructure can notify the web application that
there is room. Either that, or the push function must block when there
isn't enough space left. Further, it doesn't need to return
anything. This suggests a revision of the type:

    HeaderBlock
    -- ^ Initial request headers.
    -> (StreamContent -> IO ())
    -- ^ Function to push response content.
    -> IO (HeaderBlock, StreamContent -> IO DeltaWindowSize)
    -- ^ Response headers, function to push further request content.

## I think flow control should be hidden from the web app layer ##

After thinking about it some more, I've concluded that the details of
flow control should be hidden in the server layer. The web app layer
shouldn't need to be concerned with returning a `DeltaWindowSize`.

SPDY assumes that every stream on a connection has the same initial
data window size, and the initial window size varies only by
connection, not by stream. Given that constraint, there is nothing
clever or fancy that the web app layer can do with respect to
buffering. For example, there is no way to allocate more buffer space
to higher-priority streams, since it violates assumptions built into
the protocol. If the web app layer has to return a `DeltaWindowSize`
when it receives data, then it must ensure that we don't violate the
buffering policy, something that I think can be dealt with in the
server infrastructure. In short, making the web app layer deal with
the burden of window size deltas doesn't seem to deliver any benefits,
but it scatters the implementation of flow control over two
components, and increases the complexity of the whole.

We've already gone this route with the client, where the app must
supply a 'push' function to the client API, one that returns a
`DeltaWindowSize` value. To leave implementation options open to the
application layer, we had to permit the app to return a
`DeltaWindowSize` of zero. Consequently, we had to add the
`updateWindow` function in order to allow the app to unstall the data
stream. This function comes with a long-winded description, but it's
not clear that a client would ever need to use it in practice, or
would use it correctly.

So I think it's better to hide flow control inside the server layer,
and inside the client layer. That is, for each stream on a connection
with initial window size W, an endpoint will buffer up to W bytes in
each direction for each stream. But then what is the most natural API
for transferring data and headers between the application layers and
the infrastructure layers at each endpoint?

From the web app layer's perspective, the most natural interface would

- pull request data and headers from the server infrastructure

- push response data and headers to the server infrastructure

Or at least that's what my imperative language experience tells me
should be most natural. This is a hybrid of the approaches described
above. The type of a request handler would then look like

    HeaderBlock
    -- ^ Initial request headers.
    -> IO StreamContent
    -- ^ Action to pull subsequent data and headers.
    -> (StreamContent -> IO ())
    -- ^ Function to push response content.
    -> IO HeaderBlock
    -- ^ Response headers


I think we may need some kind of bounded buffer data structure that we
can use in a stream. That's the next thing to figure out.

## Oops. We need to support streams with empty response ##

In the last section we arrived at the response handler type

    HeaderBlock
    -- ^ Initial request headers.
    -> IO StreamContent
    -- ^ Action to pull subsequent data and headers.
    -> (StreamContent -> IO ())
    -- ^ Function to push response content.
    -> IO HeaderBlock
    -- ^ Response headers

Here, the web app layer receives functions to pull incoming request
content, and to push outgoing response content. The only problem with
this is one we've raised before: it's impossible to put the `FIN` flag
on the `SYN_REPLY` frame if all we get back is a header block.

This suggests that the more natural form of the request handler type is

    HeaderBlock
    -- ^ Initial request headers.
    -> IO StreamContent
    -- ^ Action to pull subsequent data and headers.
    -> IO (HeaderBlock, Maybe (IO StreamContent))
    -- ^ Response headers, optional action for getting response content.

Now it's the server infrastructure's responsibility to pull the
response from the web app layer. A result of the form

    (headers, Nothing)

indicates that there is no response content other than the initial set
of response headers, and so the `SYN_REPLY` frame can have the `FIN`
flag set and there is no need to extract the first piece of response
content.

Will this work for both server and client?

On the client side, the only role of a request handler is for server
push. In this case, the result will always be of the form

    (headers, Nothing)

and the headers will probably be empty. The code that pulls the
request content is really pulling a server-pushed resource into some
kind of cache. So this looks like it should be adequate.

## No need to buffer outgoing stream content ##

A couple of sections back I said

>     So I think it's better to hide flow control inside the server
>     layer, and inside the client layer. That is, for each stream on a
>     connection with initial window size W, an endpoint will buffer up
>     to W bytes in each direction for each stream.

It's not, in fact, necessary to buffer outgoing stream content. What
is necessary is tracking the remaining data window size, and it should
be fine to do this with a quantity semaphore like the one in
`Control.Concurrent.MSemN` from the SafeSemaphore package. This is
handled like so:

- a thread in the server infrastructure executes a loop that pulls the
  next stream content from the web app, takes the necessary space from
  the semaphore, and then sends the necessary frame

- the incoming reader thread handles `WINDOW_UPDATE` frames by
  signalling the availability of the new window space on the semaphore

- if a `SETTINGS` frame arrives with a new value for the window size
  on the connection, then if we have to adjust the existing streams,
  we can

    - signal the difference between the new window size and the old one
      on each semaphore

    - expand the incoming data buffers by the same difference, provided
      it is positive
